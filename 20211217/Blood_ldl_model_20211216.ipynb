{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lkC-pw0r-iXW"
      },
      "outputs": [],
      "source": [
        "#!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k_VTudIT_T2U"
      },
      "outputs": [],
      "source": [
        "__PROJECT_SOURCE__=\"COLAB\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNkYLOFrij5B",
        "outputId": "2f933ce0-01f3-4c5b-b769-7b0ab3208556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if __PROJECT_SOURCE__==\"COLAB\":\n",
        "    # Import PyDrive and associated libraries.\n",
        "    # This only needs to be done once per notebook.\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    # This only needs to be done once per notebook.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    fname_dir=\"/content/blood/\"\n",
        "    fname_url=\"/content/drive/MyDrive/blood/rework/*full.csv\"\n",
        "    fname=fname_url.split(\"/\")[-1]\n",
        "elif __PROJECT_SOURCE__==\"LOCAL\":\n",
        "    fname_dir=\"sdfsdfsd\" #working dir\n",
        "    fname_url=\"/content/drive/MyDrive/blood/rework/*agg.csv\" #data source dir\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m7yB5l-7i7dS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z3v1BBbJjBqa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zU1ZwzodjSD4"
      },
      "outputs": [],
      "source": [
        "!mkdir $fname_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vXyl_8ELjgrT"
      },
      "outputs": [],
      "source": [
        "!cp $fname_url $fname_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Y7z49_kBNx",
        "outputId": "9feb4920-65a2-4741-9a22-89e92865c152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unmount Google Drive :-(\n"
          ]
        }
      ],
      "source": [
        "if __PROJECT_SOURCE__==\"COLAB\":\n",
        "    drive.flush_and_unmount()\n",
        "    print('Unmount Google Drive :-(')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCOsDGPtxztL"
      },
      "source": [
        "## Feldolgozás"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Jy1mbPDRizA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6f5f6b-a527-4000-d966-feeeab15b6c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '*.hdf5': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm *.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LjJtfapexzDo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F6TPT1jWknJD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5MmhW6aekVHb"
      },
      "outputs": [],
      "source": [
        "fnames_list=[\"ldl1_full.csv\",\"ldl2_full.csv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YCcXLaMkrlf",
        "outputId": "7a248814-cddf-44b2-8775-04d45ab4ee01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blood/ldl1_full.csv\n"
          ]
        }
      ],
      "source": [
        "file_name1=fname_dir+fnames_list[0]\n",
        "print(file_name1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiMNf4HPBAnV",
        "outputId": "1bddda6e-ec14-4f71-8c1a-ea9118fdf971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blood/ldl2_full.csv\n"
          ]
        }
      ],
      "source": [
        "file_name2=fname_dir+fnames_list[1]\n",
        "print(file_name2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TkP2-bFrx4ra"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mPW32Ow0k9BQ"
      },
      "outputs": [],
      "source": [
        "df_agg1= pd.read_csv(file_name1)\n",
        "df_agg1.describe()\n",
        "df_agg1.drop(df_agg1[df_agg1.absorbance0 < 0].index, inplace=True) # kill the negative elements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "VSTvJ9RvzrI8",
        "outputId": "8707ff52-1b8d-4cf5-a35c-37c07d4d2678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-00c727b6-d49c-49ad-b8cc-1df90b0191ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>absorbance0</th>\n",
              "      <th>absorbance1</th>\n",
              "      <th>absorbance2</th>\n",
              "      <th>absorbance3</th>\n",
              "      <th>absorbance4</th>\n",
              "      <th>absorbance5</th>\n",
              "      <th>absorbance6</th>\n",
              "      <th>absorbance7</th>\n",
              "      <th>absorbance8</th>\n",
              "      <th>absorbance9</th>\n",
              "      <th>absorbance10</th>\n",
              "      <th>absorbance11</th>\n",
              "      <th>absorbance12</th>\n",
              "      <th>absorbance13</th>\n",
              "      <th>absorbance14</th>\n",
              "      <th>absorbance15</th>\n",
              "      <th>absorbance16</th>\n",
              "      <th>absorbance17</th>\n",
              "      <th>absorbance18</th>\n",
              "      <th>absorbance19</th>\n",
              "      <th>absorbance20</th>\n",
              "      <th>absorbance21</th>\n",
              "      <th>absorbance22</th>\n",
              "      <th>absorbance23</th>\n",
              "      <th>absorbance24</th>\n",
              "      <th>absorbance25</th>\n",
              "      <th>absorbance26</th>\n",
              "      <th>absorbance27</th>\n",
              "      <th>absorbance28</th>\n",
              "      <th>absorbance29</th>\n",
              "      <th>absorbance30</th>\n",
              "      <th>absorbance31</th>\n",
              "      <th>absorbance32</th>\n",
              "      <th>absorbance33</th>\n",
              "      <th>absorbance34</th>\n",
              "      <th>absorbance35</th>\n",
              "      <th>absorbance36</th>\n",
              "      <th>absorbance37</th>\n",
              "      <th>absorbance38</th>\n",
              "      <th>...</th>\n",
              "      <th>absorbance135</th>\n",
              "      <th>absorbance136</th>\n",
              "      <th>absorbance137</th>\n",
              "      <th>absorbance138</th>\n",
              "      <th>absorbance139</th>\n",
              "      <th>absorbance140</th>\n",
              "      <th>absorbance141</th>\n",
              "      <th>absorbance142</th>\n",
              "      <th>absorbance143</th>\n",
              "      <th>absorbance144</th>\n",
              "      <th>absorbance145</th>\n",
              "      <th>absorbance146</th>\n",
              "      <th>absorbance147</th>\n",
              "      <th>absorbance148</th>\n",
              "      <th>absorbance149</th>\n",
              "      <th>absorbance150</th>\n",
              "      <th>absorbance151</th>\n",
              "      <th>absorbance152</th>\n",
              "      <th>absorbance153</th>\n",
              "      <th>absorbance154</th>\n",
              "      <th>absorbance155</th>\n",
              "      <th>absorbance156</th>\n",
              "      <th>absorbance157</th>\n",
              "      <th>absorbance158</th>\n",
              "      <th>absorbance159</th>\n",
              "      <th>absorbance160</th>\n",
              "      <th>absorbance161</th>\n",
              "      <th>absorbance162</th>\n",
              "      <th>absorbance163</th>\n",
              "      <th>absorbance164</th>\n",
              "      <th>absorbance165</th>\n",
              "      <th>absorbance166</th>\n",
              "      <th>absorbance167</th>\n",
              "      <th>absorbance168</th>\n",
              "      <th>absorbance169</th>\n",
              "      <th>donation_id</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>cholesterol_ldl_value</th>\n",
              "      <th>cholesterol_ldl_human</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.555104</td>\n",
              "      <td>0.557888</td>\n",
              "      <td>0.560819</td>\n",
              "      <td>0.564807</td>\n",
              "      <td>0.569713</td>\n",
              "      <td>0.571515</td>\n",
              "      <td>0.575181</td>\n",
              "      <td>0.584829</td>\n",
              "      <td>0.593431</td>\n",
              "      <td>0.605127</td>\n",
              "      <td>0.618471</td>\n",
              "      <td>0.629546</td>\n",
              "      <td>0.636551</td>\n",
              "      <td>0.640862</td>\n",
              "      <td>0.641604</td>\n",
              "      <td>0.641446</td>\n",
              "      <td>0.640700</td>\n",
              "      <td>0.638512</td>\n",
              "      <td>0.634634</td>\n",
              "      <td>0.632141</td>\n",
              "      <td>0.628197</td>\n",
              "      <td>0.624323</td>\n",
              "      <td>0.621635</td>\n",
              "      <td>0.618258</td>\n",
              "      <td>0.615647</td>\n",
              "      <td>0.610852</td>\n",
              "      <td>0.607246</td>\n",
              "      <td>0.607107</td>\n",
              "      <td>0.603485</td>\n",
              "      <td>0.601846</td>\n",
              "      <td>0.600708</td>\n",
              "      <td>0.601836</td>\n",
              "      <td>0.602374</td>\n",
              "      <td>0.603096</td>\n",
              "      <td>0.603789</td>\n",
              "      <td>0.606727</td>\n",
              "      <td>0.609770</td>\n",
              "      <td>0.613277</td>\n",
              "      <td>0.617720</td>\n",
              "      <td>...</td>\n",
              "      <td>1.520773</td>\n",
              "      <td>1.510931</td>\n",
              "      <td>1.492422</td>\n",
              "      <td>1.490522</td>\n",
              "      <td>1.483260</td>\n",
              "      <td>1.466496</td>\n",
              "      <td>1.446990</td>\n",
              "      <td>1.446223</td>\n",
              "      <td>1.436076</td>\n",
              "      <td>1.430866</td>\n",
              "      <td>1.415027</td>\n",
              "      <td>1.405551</td>\n",
              "      <td>1.398514</td>\n",
              "      <td>1.384277</td>\n",
              "      <td>1.380456</td>\n",
              "      <td>1.384401</td>\n",
              "      <td>1.365411</td>\n",
              "      <td>1.366780</td>\n",
              "      <td>1.362377</td>\n",
              "      <td>1.347071</td>\n",
              "      <td>1.345513</td>\n",
              "      <td>1.344558</td>\n",
              "      <td>1.342451</td>\n",
              "      <td>1.334845</td>\n",
              "      <td>1.332185</td>\n",
              "      <td>1.332433</td>\n",
              "      <td>1.338564</td>\n",
              "      <td>1.347783</td>\n",
              "      <td>1.326137</td>\n",
              "      <td>1.330770</td>\n",
              "      <td>1.339941</td>\n",
              "      <td>1.359609</td>\n",
              "      <td>1.362426</td>\n",
              "      <td>1.363026</td>\n",
              "      <td>1.342270</td>\n",
              "      <td>10908</td>\n",
              "      <td>36.46</td>\n",
              "      <td>52.76</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.555762</td>\n",
              "      <td>0.560531</td>\n",
              "      <td>0.558478</td>\n",
              "      <td>0.562081</td>\n",
              "      <td>0.562192</td>\n",
              "      <td>0.570873</td>\n",
              "      <td>0.577154</td>\n",
              "      <td>0.582132</td>\n",
              "      <td>0.593250</td>\n",
              "      <td>0.603150</td>\n",
              "      <td>0.617897</td>\n",
              "      <td>0.628655</td>\n",
              "      <td>0.636400</td>\n",
              "      <td>0.640521</td>\n",
              "      <td>0.640574</td>\n",
              "      <td>0.640428</td>\n",
              "      <td>0.639644</td>\n",
              "      <td>0.637355</td>\n",
              "      <td>0.635599</td>\n",
              "      <td>0.630248</td>\n",
              "      <td>0.627635</td>\n",
              "      <td>0.622413</td>\n",
              "      <td>0.620346</td>\n",
              "      <td>0.616633</td>\n",
              "      <td>0.612760</td>\n",
              "      <td>0.609439</td>\n",
              "      <td>0.606312</td>\n",
              "      <td>0.604100</td>\n",
              "      <td>0.602474</td>\n",
              "      <td>0.601674</td>\n",
              "      <td>0.600377</td>\n",
              "      <td>0.600369</td>\n",
              "      <td>0.601505</td>\n",
              "      <td>0.601641</td>\n",
              "      <td>0.603493</td>\n",
              "      <td>0.605021</td>\n",
              "      <td>0.609614</td>\n",
              "      <td>0.612522</td>\n",
              "      <td>0.616560</td>\n",
              "      <td>...</td>\n",
              "      <td>1.526411</td>\n",
              "      <td>1.502567</td>\n",
              "      <td>1.497602</td>\n",
              "      <td>1.485082</td>\n",
              "      <td>1.481636</td>\n",
              "      <td>1.464493</td>\n",
              "      <td>1.456803</td>\n",
              "      <td>1.441662</td>\n",
              "      <td>1.438423</td>\n",
              "      <td>1.424229</td>\n",
              "      <td>1.419714</td>\n",
              "      <td>1.400824</td>\n",
              "      <td>1.403250</td>\n",
              "      <td>1.397352</td>\n",
              "      <td>1.379809</td>\n",
              "      <td>1.376884</td>\n",
              "      <td>1.367898</td>\n",
              "      <td>1.360034</td>\n",
              "      <td>1.355922</td>\n",
              "      <td>1.349818</td>\n",
              "      <td>1.338001</td>\n",
              "      <td>1.330943</td>\n",
              "      <td>1.335373</td>\n",
              "      <td>1.332000</td>\n",
              "      <td>1.333735</td>\n",
              "      <td>1.335764</td>\n",
              "      <td>1.333988</td>\n",
              "      <td>1.306720</td>\n",
              "      <td>1.347984</td>\n",
              "      <td>1.343536</td>\n",
              "      <td>1.338133</td>\n",
              "      <td>1.331781</td>\n",
              "      <td>1.333470</td>\n",
              "      <td>1.327370</td>\n",
              "      <td>1.339093</td>\n",
              "      <td>10908</td>\n",
              "      <td>36.58</td>\n",
              "      <td>52.64</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.562597</td>\n",
              "      <td>0.562343</td>\n",
              "      <td>0.568340</td>\n",
              "      <td>0.566400</td>\n",
              "      <td>0.572975</td>\n",
              "      <td>0.578334</td>\n",
              "      <td>0.580465</td>\n",
              "      <td>0.589982</td>\n",
              "      <td>0.598328</td>\n",
              "      <td>0.610434</td>\n",
              "      <td>0.623061</td>\n",
              "      <td>0.633923</td>\n",
              "      <td>0.640617</td>\n",
              "      <td>0.642912</td>\n",
              "      <td>0.644928</td>\n",
              "      <td>0.645464</td>\n",
              "      <td>0.643183</td>\n",
              "      <td>0.641556</td>\n",
              "      <td>0.636517</td>\n",
              "      <td>0.634591</td>\n",
              "      <td>0.630620</td>\n",
              "      <td>0.625786</td>\n",
              "      <td>0.622011</td>\n",
              "      <td>0.619110</td>\n",
              "      <td>0.616875</td>\n",
              "      <td>0.612358</td>\n",
              "      <td>0.608903</td>\n",
              "      <td>0.606762</td>\n",
              "      <td>0.605808</td>\n",
              "      <td>0.603580</td>\n",
              "      <td>0.602655</td>\n",
              "      <td>0.603412</td>\n",
              "      <td>0.602630</td>\n",
              "      <td>0.605225</td>\n",
              "      <td>0.605887</td>\n",
              "      <td>0.607095</td>\n",
              "      <td>0.610909</td>\n",
              "      <td>0.615698</td>\n",
              "      <td>0.617958</td>\n",
              "      <td>...</td>\n",
              "      <td>1.528323</td>\n",
              "      <td>1.507033</td>\n",
              "      <td>1.496102</td>\n",
              "      <td>1.487758</td>\n",
              "      <td>1.477625</td>\n",
              "      <td>1.474076</td>\n",
              "      <td>1.458480</td>\n",
              "      <td>1.446704</td>\n",
              "      <td>1.432638</td>\n",
              "      <td>1.423987</td>\n",
              "      <td>1.406735</td>\n",
              "      <td>1.411351</td>\n",
              "      <td>1.396077</td>\n",
              "      <td>1.393421</td>\n",
              "      <td>1.381700</td>\n",
              "      <td>1.370491</td>\n",
              "      <td>1.374372</td>\n",
              "      <td>1.373860</td>\n",
              "      <td>1.356037</td>\n",
              "      <td>1.354704</td>\n",
              "      <td>1.337940</td>\n",
              "      <td>1.345736</td>\n",
              "      <td>1.332683</td>\n",
              "      <td>1.337675</td>\n",
              "      <td>1.339260</td>\n",
              "      <td>1.342463</td>\n",
              "      <td>1.326266</td>\n",
              "      <td>1.329472</td>\n",
              "      <td>1.346833</td>\n",
              "      <td>1.337076</td>\n",
              "      <td>1.360504</td>\n",
              "      <td>1.335544</td>\n",
              "      <td>1.349121</td>\n",
              "      <td>1.351695</td>\n",
              "      <td>1.353211</td>\n",
              "      <td>10908</td>\n",
              "      <td>36.72</td>\n",
              "      <td>52.54</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.561160</td>\n",
              "      <td>0.560216</td>\n",
              "      <td>0.561439</td>\n",
              "      <td>0.566591</td>\n",
              "      <td>0.570579</td>\n",
              "      <td>0.573371</td>\n",
              "      <td>0.580483</td>\n",
              "      <td>0.589868</td>\n",
              "      <td>0.598581</td>\n",
              "      <td>0.609787</td>\n",
              "      <td>0.621992</td>\n",
              "      <td>0.632943</td>\n",
              "      <td>0.639635</td>\n",
              "      <td>0.644243</td>\n",
              "      <td>0.645487</td>\n",
              "      <td>0.645152</td>\n",
              "      <td>0.644481</td>\n",
              "      <td>0.640507</td>\n",
              "      <td>0.637796</td>\n",
              "      <td>0.635107</td>\n",
              "      <td>0.630688</td>\n",
              "      <td>0.626547</td>\n",
              "      <td>0.622671</td>\n",
              "      <td>0.619277</td>\n",
              "      <td>0.616344</td>\n",
              "      <td>0.611148</td>\n",
              "      <td>0.608747</td>\n",
              "      <td>0.606468</td>\n",
              "      <td>0.605317</td>\n",
              "      <td>0.604573</td>\n",
              "      <td>0.601598</td>\n",
              "      <td>0.603415</td>\n",
              "      <td>0.602356</td>\n",
              "      <td>0.604682</td>\n",
              "      <td>0.605558</td>\n",
              "      <td>0.607304</td>\n",
              "      <td>0.610898</td>\n",
              "      <td>0.614099</td>\n",
              "      <td>0.618129</td>\n",
              "      <td>...</td>\n",
              "      <td>1.513074</td>\n",
              "      <td>1.508274</td>\n",
              "      <td>1.491448</td>\n",
              "      <td>1.491685</td>\n",
              "      <td>1.475292</td>\n",
              "      <td>1.468794</td>\n",
              "      <td>1.450865</td>\n",
              "      <td>1.449815</td>\n",
              "      <td>1.441932</td>\n",
              "      <td>1.424617</td>\n",
              "      <td>1.425701</td>\n",
              "      <td>1.408045</td>\n",
              "      <td>1.398489</td>\n",
              "      <td>1.389195</td>\n",
              "      <td>1.383651</td>\n",
              "      <td>1.373491</td>\n",
              "      <td>1.374069</td>\n",
              "      <td>1.354400</td>\n",
              "      <td>1.348482</td>\n",
              "      <td>1.343348</td>\n",
              "      <td>1.344841</td>\n",
              "      <td>1.344812</td>\n",
              "      <td>1.338079</td>\n",
              "      <td>1.335832</td>\n",
              "      <td>1.334965</td>\n",
              "      <td>1.331633</td>\n",
              "      <td>1.338109</td>\n",
              "      <td>1.336605</td>\n",
              "      <td>1.328783</td>\n",
              "      <td>1.333058</td>\n",
              "      <td>1.337232</td>\n",
              "      <td>1.319352</td>\n",
              "      <td>1.374021</td>\n",
              "      <td>1.375438</td>\n",
              "      <td>1.340502</td>\n",
              "      <td>10908</td>\n",
              "      <td>36.83</td>\n",
              "      <td>52.48</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.562610</td>\n",
              "      <td>0.565366</td>\n",
              "      <td>0.564041</td>\n",
              "      <td>0.568373</td>\n",
              "      <td>0.573241</td>\n",
              "      <td>0.577843</td>\n",
              "      <td>0.583221</td>\n",
              "      <td>0.590243</td>\n",
              "      <td>0.601484</td>\n",
              "      <td>0.611506</td>\n",
              "      <td>0.623042</td>\n",
              "      <td>0.635075</td>\n",
              "      <td>0.641987</td>\n",
              "      <td>0.644165</td>\n",
              "      <td>0.645974</td>\n",
              "      <td>0.645572</td>\n",
              "      <td>0.644620</td>\n",
              "      <td>0.643276</td>\n",
              "      <td>0.638574</td>\n",
              "      <td>0.634793</td>\n",
              "      <td>0.631465</td>\n",
              "      <td>0.628525</td>\n",
              "      <td>0.624174</td>\n",
              "      <td>0.619503</td>\n",
              "      <td>0.617375</td>\n",
              "      <td>0.613522</td>\n",
              "      <td>0.610343</td>\n",
              "      <td>0.608390</td>\n",
              "      <td>0.607009</td>\n",
              "      <td>0.604699</td>\n",
              "      <td>0.603621</td>\n",
              "      <td>0.603209</td>\n",
              "      <td>0.604488</td>\n",
              "      <td>0.605994</td>\n",
              "      <td>0.605787</td>\n",
              "      <td>0.608542</td>\n",
              "      <td>0.611572</td>\n",
              "      <td>0.614894</td>\n",
              "      <td>0.619644</td>\n",
              "      <td>...</td>\n",
              "      <td>1.528586</td>\n",
              "      <td>1.513321</td>\n",
              "      <td>1.505730</td>\n",
              "      <td>1.493996</td>\n",
              "      <td>1.480969</td>\n",
              "      <td>1.472204</td>\n",
              "      <td>1.462411</td>\n",
              "      <td>1.445528</td>\n",
              "      <td>1.443402</td>\n",
              "      <td>1.436011</td>\n",
              "      <td>1.424402</td>\n",
              "      <td>1.409757</td>\n",
              "      <td>1.404730</td>\n",
              "      <td>1.395356</td>\n",
              "      <td>1.392342</td>\n",
              "      <td>1.382428</td>\n",
              "      <td>1.379855</td>\n",
              "      <td>1.364706</td>\n",
              "      <td>1.359195</td>\n",
              "      <td>1.347100</td>\n",
              "      <td>1.341862</td>\n",
              "      <td>1.348678</td>\n",
              "      <td>1.347436</td>\n",
              "      <td>1.342283</td>\n",
              "      <td>1.331358</td>\n",
              "      <td>1.343871</td>\n",
              "      <td>1.341100</td>\n",
              "      <td>1.341243</td>\n",
              "      <td>1.349242</td>\n",
              "      <td>1.359243</td>\n",
              "      <td>1.362488</td>\n",
              "      <td>1.361758</td>\n",
              "      <td>1.395285</td>\n",
              "      <td>1.415294</td>\n",
              "      <td>1.373094</td>\n",
              "      <td>10908</td>\n",
              "      <td>36.93</td>\n",
              "      <td>52.37</td>\n",
              "      <td>31.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 176 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00c727b6-d49c-49ad-b8cc-1df90b0191ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00c727b6-d49c-49ad-b8cc-1df90b0191ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00c727b6-d49c-49ad-b8cc-1df90b0191ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  absorbance0  ...  cholesterol_ldl_value  cholesterol_ldl_human\n",
              "0           0     0.555104  ...                   31.9                      0\n",
              "1           1     0.555762  ...                   31.9                      0\n",
              "2           2     0.562597  ...                   31.9                      0\n",
              "3           3     0.561160  ...                   31.9                      0\n",
              "4           4     0.562610  ...                   31.9                      0\n",
              "\n",
              "[5 rows x 176 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_agg1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VbOP7ZtiBKBM"
      },
      "outputs": [],
      "source": [
        "df_agg2= pd.read_csv(file_name2)\n",
        "df_agg2.describe()\n",
        "df_agg2.drop(df_agg2[df_agg2.absorbance0 < 0].index, inplace=True) # kill the negative elements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6hFjkYViA-Di"
      },
      "outputs": [],
      "source": [
        "df_agg=pd.concat([df_agg1,df_agg2], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "Y5xTiFTT0r-n",
        "outputId": "2dc678f2-52ac-4bca-a10a-2c903874e882"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-702c8229-c90f-4a09-b82e-78889e96c280\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>absorbance0</th>\n",
              "      <th>absorbance1</th>\n",
              "      <th>absorbance2</th>\n",
              "      <th>absorbance3</th>\n",
              "      <th>absorbance4</th>\n",
              "      <th>absorbance5</th>\n",
              "      <th>absorbance6</th>\n",
              "      <th>absorbance7</th>\n",
              "      <th>absorbance8</th>\n",
              "      <th>absorbance9</th>\n",
              "      <th>absorbance10</th>\n",
              "      <th>absorbance11</th>\n",
              "      <th>absorbance12</th>\n",
              "      <th>absorbance13</th>\n",
              "      <th>absorbance14</th>\n",
              "      <th>absorbance15</th>\n",
              "      <th>absorbance16</th>\n",
              "      <th>absorbance17</th>\n",
              "      <th>absorbance18</th>\n",
              "      <th>absorbance19</th>\n",
              "      <th>absorbance20</th>\n",
              "      <th>absorbance21</th>\n",
              "      <th>absorbance22</th>\n",
              "      <th>absorbance23</th>\n",
              "      <th>absorbance24</th>\n",
              "      <th>absorbance25</th>\n",
              "      <th>absorbance26</th>\n",
              "      <th>absorbance27</th>\n",
              "      <th>absorbance28</th>\n",
              "      <th>absorbance29</th>\n",
              "      <th>absorbance30</th>\n",
              "      <th>absorbance31</th>\n",
              "      <th>absorbance32</th>\n",
              "      <th>absorbance33</th>\n",
              "      <th>absorbance34</th>\n",
              "      <th>absorbance35</th>\n",
              "      <th>absorbance36</th>\n",
              "      <th>absorbance37</th>\n",
              "      <th>absorbance38</th>\n",
              "      <th>...</th>\n",
              "      <th>absorbance135</th>\n",
              "      <th>absorbance136</th>\n",
              "      <th>absorbance137</th>\n",
              "      <th>absorbance138</th>\n",
              "      <th>absorbance139</th>\n",
              "      <th>absorbance140</th>\n",
              "      <th>absorbance141</th>\n",
              "      <th>absorbance142</th>\n",
              "      <th>absorbance143</th>\n",
              "      <th>absorbance144</th>\n",
              "      <th>absorbance145</th>\n",
              "      <th>absorbance146</th>\n",
              "      <th>absorbance147</th>\n",
              "      <th>absorbance148</th>\n",
              "      <th>absorbance149</th>\n",
              "      <th>absorbance150</th>\n",
              "      <th>absorbance151</th>\n",
              "      <th>absorbance152</th>\n",
              "      <th>absorbance153</th>\n",
              "      <th>absorbance154</th>\n",
              "      <th>absorbance155</th>\n",
              "      <th>absorbance156</th>\n",
              "      <th>absorbance157</th>\n",
              "      <th>absorbance158</th>\n",
              "      <th>absorbance159</th>\n",
              "      <th>absorbance160</th>\n",
              "      <th>absorbance161</th>\n",
              "      <th>absorbance162</th>\n",
              "      <th>absorbance163</th>\n",
              "      <th>absorbance164</th>\n",
              "      <th>absorbance165</th>\n",
              "      <th>absorbance166</th>\n",
              "      <th>absorbance167</th>\n",
              "      <th>absorbance168</th>\n",
              "      <th>absorbance169</th>\n",
              "      <th>donation_id</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>cholesterol_ldl_value</th>\n",
              "      <th>cholesterol_ldl_human</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32515</th>\n",
              "      <td>24595</td>\n",
              "      <td>0.506018</td>\n",
              "      <td>0.511588</td>\n",
              "      <td>0.514728</td>\n",
              "      <td>0.522995</td>\n",
              "      <td>0.522961</td>\n",
              "      <td>0.530508</td>\n",
              "      <td>0.537877</td>\n",
              "      <td>0.543076</td>\n",
              "      <td>0.554601</td>\n",
              "      <td>0.568389</td>\n",
              "      <td>0.582809</td>\n",
              "      <td>0.591292</td>\n",
              "      <td>0.599365</td>\n",
              "      <td>0.601744</td>\n",
              "      <td>0.602022</td>\n",
              "      <td>0.603138</td>\n",
              "      <td>0.600151</td>\n",
              "      <td>0.597552</td>\n",
              "      <td>0.594863</td>\n",
              "      <td>0.590940</td>\n",
              "      <td>0.586909</td>\n",
              "      <td>0.583157</td>\n",
              "      <td>0.579254</td>\n",
              "      <td>0.576506</td>\n",
              "      <td>0.570974</td>\n",
              "      <td>0.568377</td>\n",
              "      <td>0.565177</td>\n",
              "      <td>0.562761</td>\n",
              "      <td>0.561213</td>\n",
              "      <td>0.559032</td>\n",
              "      <td>0.557812</td>\n",
              "      <td>0.557912</td>\n",
              "      <td>0.557015</td>\n",
              "      <td>0.557685</td>\n",
              "      <td>0.560666</td>\n",
              "      <td>0.561338</td>\n",
              "      <td>0.563833</td>\n",
              "      <td>0.568147</td>\n",
              "      <td>0.570612</td>\n",
              "      <td>...</td>\n",
              "      <td>1.511238</td>\n",
              "      <td>1.505166</td>\n",
              "      <td>1.490777</td>\n",
              "      <td>1.479463</td>\n",
              "      <td>1.465389</td>\n",
              "      <td>1.454685</td>\n",
              "      <td>1.443616</td>\n",
              "      <td>1.434122</td>\n",
              "      <td>1.426536</td>\n",
              "      <td>1.415761</td>\n",
              "      <td>1.405067</td>\n",
              "      <td>1.397242</td>\n",
              "      <td>1.379932</td>\n",
              "      <td>1.373153</td>\n",
              "      <td>1.364595</td>\n",
              "      <td>1.359029</td>\n",
              "      <td>1.356389</td>\n",
              "      <td>1.352608</td>\n",
              "      <td>1.339140</td>\n",
              "      <td>1.333420</td>\n",
              "      <td>1.324067</td>\n",
              "      <td>1.321493</td>\n",
              "      <td>1.325140</td>\n",
              "      <td>1.333179</td>\n",
              "      <td>1.322949</td>\n",
              "      <td>1.313297</td>\n",
              "      <td>1.329096</td>\n",
              "      <td>1.313718</td>\n",
              "      <td>1.328141</td>\n",
              "      <td>1.324515</td>\n",
              "      <td>1.325210</td>\n",
              "      <td>1.304364</td>\n",
              "      <td>1.303733</td>\n",
              "      <td>1.311444</td>\n",
              "      <td>1.426517</td>\n",
              "      <td>1974</td>\n",
              "      <td>40.75</td>\n",
              "      <td>40.18</td>\n",
              "      <td>130.2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32516</th>\n",
              "      <td>24596</td>\n",
              "      <td>0.507788</td>\n",
              "      <td>0.515130</td>\n",
              "      <td>0.514383</td>\n",
              "      <td>0.516559</td>\n",
              "      <td>0.524998</td>\n",
              "      <td>0.530050</td>\n",
              "      <td>0.537561</td>\n",
              "      <td>0.542864</td>\n",
              "      <td>0.555810</td>\n",
              "      <td>0.568044</td>\n",
              "      <td>0.582369</td>\n",
              "      <td>0.592729</td>\n",
              "      <td>0.599622</td>\n",
              "      <td>0.601999</td>\n",
              "      <td>0.602173</td>\n",
              "      <td>0.601870</td>\n",
              "      <td>0.600475</td>\n",
              "      <td>0.598526</td>\n",
              "      <td>0.595201</td>\n",
              "      <td>0.590471</td>\n",
              "      <td>0.586986</td>\n",
              "      <td>0.583303</td>\n",
              "      <td>0.579900</td>\n",
              "      <td>0.576040</td>\n",
              "      <td>0.571166</td>\n",
              "      <td>0.567999</td>\n",
              "      <td>0.565082</td>\n",
              "      <td>0.563578</td>\n",
              "      <td>0.560635</td>\n",
              "      <td>0.559509</td>\n",
              "      <td>0.557579</td>\n",
              "      <td>0.557783</td>\n",
              "      <td>0.556996</td>\n",
              "      <td>0.556796</td>\n",
              "      <td>0.559637</td>\n",
              "      <td>0.561540</td>\n",
              "      <td>0.564576</td>\n",
              "      <td>0.567907</td>\n",
              "      <td>0.571838</td>\n",
              "      <td>...</td>\n",
              "      <td>1.517297</td>\n",
              "      <td>1.504995</td>\n",
              "      <td>1.497658</td>\n",
              "      <td>1.485209</td>\n",
              "      <td>1.468672</td>\n",
              "      <td>1.460962</td>\n",
              "      <td>1.454316</td>\n",
              "      <td>1.433358</td>\n",
              "      <td>1.422211</td>\n",
              "      <td>1.421244</td>\n",
              "      <td>1.412109</td>\n",
              "      <td>1.397289</td>\n",
              "      <td>1.385969</td>\n",
              "      <td>1.381461</td>\n",
              "      <td>1.369660</td>\n",
              "      <td>1.365378</td>\n",
              "      <td>1.355046</td>\n",
              "      <td>1.351141</td>\n",
              "      <td>1.348660</td>\n",
              "      <td>1.334184</td>\n",
              "      <td>1.331807</td>\n",
              "      <td>1.329454</td>\n",
              "      <td>1.328735</td>\n",
              "      <td>1.320480</td>\n",
              "      <td>1.321458</td>\n",
              "      <td>1.331778</td>\n",
              "      <td>1.334629</td>\n",
              "      <td>1.324187</td>\n",
              "      <td>1.316435</td>\n",
              "      <td>1.330567</td>\n",
              "      <td>1.317782</td>\n",
              "      <td>1.328589</td>\n",
              "      <td>1.338975</td>\n",
              "      <td>1.338410</td>\n",
              "      <td>1.306974</td>\n",
              "      <td>1974</td>\n",
              "      <td>40.82</td>\n",
              "      <td>40.13</td>\n",
              "      <td>130.2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32517</th>\n",
              "      <td>24597</td>\n",
              "      <td>0.507435</td>\n",
              "      <td>0.509331</td>\n",
              "      <td>0.511466</td>\n",
              "      <td>0.520766</td>\n",
              "      <td>0.523352</td>\n",
              "      <td>0.528844</td>\n",
              "      <td>0.534432</td>\n",
              "      <td>0.541395</td>\n",
              "      <td>0.553505</td>\n",
              "      <td>0.566188</td>\n",
              "      <td>0.580461</td>\n",
              "      <td>0.591363</td>\n",
              "      <td>0.598073</td>\n",
              "      <td>0.598689</td>\n",
              "      <td>0.601007</td>\n",
              "      <td>0.600427</td>\n",
              "      <td>0.599137</td>\n",
              "      <td>0.595049</td>\n",
              "      <td>0.592260</td>\n",
              "      <td>0.589254</td>\n",
              "      <td>0.584750</td>\n",
              "      <td>0.581037</td>\n",
              "      <td>0.577817</td>\n",
              "      <td>0.574073</td>\n",
              "      <td>0.570079</td>\n",
              "      <td>0.566629</td>\n",
              "      <td>0.563921</td>\n",
              "      <td>0.562093</td>\n",
              "      <td>0.559176</td>\n",
              "      <td>0.558484</td>\n",
              "      <td>0.557063</td>\n",
              "      <td>0.555998</td>\n",
              "      <td>0.556070</td>\n",
              "      <td>0.556430</td>\n",
              "      <td>0.558351</td>\n",
              "      <td>0.559575</td>\n",
              "      <td>0.563627</td>\n",
              "      <td>0.566719</td>\n",
              "      <td>0.569755</td>\n",
              "      <td>...</td>\n",
              "      <td>1.520466</td>\n",
              "      <td>1.506067</td>\n",
              "      <td>1.488761</td>\n",
              "      <td>1.481726</td>\n",
              "      <td>1.469406</td>\n",
              "      <td>1.460918</td>\n",
              "      <td>1.450390</td>\n",
              "      <td>1.440174</td>\n",
              "      <td>1.426757</td>\n",
              "      <td>1.421634</td>\n",
              "      <td>1.404178</td>\n",
              "      <td>1.401206</td>\n",
              "      <td>1.391210</td>\n",
              "      <td>1.384144</td>\n",
              "      <td>1.370918</td>\n",
              "      <td>1.362318</td>\n",
              "      <td>1.356493</td>\n",
              "      <td>1.354322</td>\n",
              "      <td>1.332693</td>\n",
              "      <td>1.332460</td>\n",
              "      <td>1.331159</td>\n",
              "      <td>1.326356</td>\n",
              "      <td>1.321987</td>\n",
              "      <td>1.332561</td>\n",
              "      <td>1.326842</td>\n",
              "      <td>1.329386</td>\n",
              "      <td>1.321799</td>\n",
              "      <td>1.317739</td>\n",
              "      <td>1.322352</td>\n",
              "      <td>1.335085</td>\n",
              "      <td>1.335843</td>\n",
              "      <td>1.302808</td>\n",
              "      <td>1.314103</td>\n",
              "      <td>1.333720</td>\n",
              "      <td>1.365253</td>\n",
              "      <td>1974</td>\n",
              "      <td>40.87</td>\n",
              "      <td>40.08</td>\n",
              "      <td>130.2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32518</th>\n",
              "      <td>24598</td>\n",
              "      <td>0.504340</td>\n",
              "      <td>0.512301</td>\n",
              "      <td>0.514911</td>\n",
              "      <td>0.517578</td>\n",
              "      <td>0.525679</td>\n",
              "      <td>0.529063</td>\n",
              "      <td>0.535851</td>\n",
              "      <td>0.540529</td>\n",
              "      <td>0.551863</td>\n",
              "      <td>0.566400</td>\n",
              "      <td>0.580162</td>\n",
              "      <td>0.590489</td>\n",
              "      <td>0.596986</td>\n",
              "      <td>0.598853</td>\n",
              "      <td>0.600226</td>\n",
              "      <td>0.599622</td>\n",
              "      <td>0.597620</td>\n",
              "      <td>0.596002</td>\n",
              "      <td>0.591475</td>\n",
              "      <td>0.588685</td>\n",
              "      <td>0.584692</td>\n",
              "      <td>0.581810</td>\n",
              "      <td>0.576919</td>\n",
              "      <td>0.572615</td>\n",
              "      <td>0.570243</td>\n",
              "      <td>0.566556</td>\n",
              "      <td>0.563359</td>\n",
              "      <td>0.561002</td>\n",
              "      <td>0.560049</td>\n",
              "      <td>0.557929</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556340</td>\n",
              "      <td>0.555732</td>\n",
              "      <td>0.556763</td>\n",
              "      <td>0.557205</td>\n",
              "      <td>0.559490</td>\n",
              "      <td>0.562675</td>\n",
              "      <td>0.566376</td>\n",
              "      <td>0.570217</td>\n",
              "      <td>...</td>\n",
              "      <td>1.517641</td>\n",
              "      <td>1.507594</td>\n",
              "      <td>1.493915</td>\n",
              "      <td>1.484648</td>\n",
              "      <td>1.471439</td>\n",
              "      <td>1.460701</td>\n",
              "      <td>1.456381</td>\n",
              "      <td>1.432987</td>\n",
              "      <td>1.420348</td>\n",
              "      <td>1.413911</td>\n",
              "      <td>1.410280</td>\n",
              "      <td>1.389240</td>\n",
              "      <td>1.387780</td>\n",
              "      <td>1.384702</td>\n",
              "      <td>1.375359</td>\n",
              "      <td>1.362545</td>\n",
              "      <td>1.351091</td>\n",
              "      <td>1.346058</td>\n",
              "      <td>1.352913</td>\n",
              "      <td>1.341091</td>\n",
              "      <td>1.325575</td>\n",
              "      <td>1.331336</td>\n",
              "      <td>1.336737</td>\n",
              "      <td>1.325752</td>\n",
              "      <td>1.333823</td>\n",
              "      <td>1.327902</td>\n",
              "      <td>1.333474</td>\n",
              "      <td>1.325987</td>\n",
              "      <td>1.323078</td>\n",
              "      <td>1.320766</td>\n",
              "      <td>1.305506</td>\n",
              "      <td>1.317392</td>\n",
              "      <td>1.308363</td>\n",
              "      <td>1.303539</td>\n",
              "      <td>1.309175</td>\n",
              "      <td>1974</td>\n",
              "      <td>40.94</td>\n",
              "      <td>40.02</td>\n",
              "      <td>130.2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32519</th>\n",
              "      <td>24599</td>\n",
              "      <td>0.505921</td>\n",
              "      <td>0.509828</td>\n",
              "      <td>0.512678</td>\n",
              "      <td>0.519219</td>\n",
              "      <td>0.523278</td>\n",
              "      <td>0.531142</td>\n",
              "      <td>0.535303</td>\n",
              "      <td>0.542502</td>\n",
              "      <td>0.553941</td>\n",
              "      <td>0.566396</td>\n",
              "      <td>0.579976</td>\n",
              "      <td>0.590890</td>\n",
              "      <td>0.597675</td>\n",
              "      <td>0.598983</td>\n",
              "      <td>0.600499</td>\n",
              "      <td>0.600132</td>\n",
              "      <td>0.598307</td>\n",
              "      <td>0.596581</td>\n",
              "      <td>0.591931</td>\n",
              "      <td>0.589182</td>\n",
              "      <td>0.584422</td>\n",
              "      <td>0.581382</td>\n",
              "      <td>0.577587</td>\n",
              "      <td>0.573717</td>\n",
              "      <td>0.569469</td>\n",
              "      <td>0.565508</td>\n",
              "      <td>0.562560</td>\n",
              "      <td>0.561536</td>\n",
              "      <td>0.559027</td>\n",
              "      <td>0.557004</td>\n",
              "      <td>0.556521</td>\n",
              "      <td>0.556072</td>\n",
              "      <td>0.556007</td>\n",
              "      <td>0.555712</td>\n",
              "      <td>0.558220</td>\n",
              "      <td>0.560628</td>\n",
              "      <td>0.563942</td>\n",
              "      <td>0.566587</td>\n",
              "      <td>0.571150</td>\n",
              "      <td>...</td>\n",
              "      <td>1.521767</td>\n",
              "      <td>1.505488</td>\n",
              "      <td>1.493230</td>\n",
              "      <td>1.484583</td>\n",
              "      <td>1.470897</td>\n",
              "      <td>1.456904</td>\n",
              "      <td>1.450325</td>\n",
              "      <td>1.437457</td>\n",
              "      <td>1.423574</td>\n",
              "      <td>1.415309</td>\n",
              "      <td>1.406393</td>\n",
              "      <td>1.400667</td>\n",
              "      <td>1.384820</td>\n",
              "      <td>1.376715</td>\n",
              "      <td>1.371239</td>\n",
              "      <td>1.367107</td>\n",
              "      <td>1.353449</td>\n",
              "      <td>1.349466</td>\n",
              "      <td>1.345271</td>\n",
              "      <td>1.353819</td>\n",
              "      <td>1.325778</td>\n",
              "      <td>1.332481</td>\n",
              "      <td>1.331159</td>\n",
              "      <td>1.324302</td>\n",
              "      <td>1.314392</td>\n",
              "      <td>1.318645</td>\n",
              "      <td>1.326566</td>\n",
              "      <td>1.331013</td>\n",
              "      <td>1.336142</td>\n",
              "      <td>1.298990</td>\n",
              "      <td>1.318010</td>\n",
              "      <td>1.294036</td>\n",
              "      <td>1.365093</td>\n",
              "      <td>1.349394</td>\n",
              "      <td>1.354708</td>\n",
              "      <td>1974</td>\n",
              "      <td>41.00</td>\n",
              "      <td>39.97</td>\n",
              "      <td>130.2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 176 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-702c8229-c90f-4a09-b82e-78889e96c280')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-702c8229-c90f-4a09-b82e-78889e96c280 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-702c8229-c90f-4a09-b82e-78889e96c280');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0  absorbance0  ...  cholesterol_ldl_value  cholesterol_ldl_human\n",
              "32515       24595     0.506018  ...                  130.2                      3\n",
              "32516       24596     0.507788  ...                  130.2                      3\n",
              "32517       24597     0.507435  ...                  130.2                      3\n",
              "32518       24598     0.504340  ...                  130.2                      3\n",
              "32519       24599     0.505921  ...                  130.2                      3\n",
              "\n",
              "[5 rows x 176 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_agg.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "NzXlFWOu0W2K",
        "outputId": "35d8dba5-9652-4797-dbda-54509d26c965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1e97eae-2b8b-4658-a992-1d45b8b4bec6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>absorbance0</th>\n",
              "      <th>absorbance1</th>\n",
              "      <th>absorbance2</th>\n",
              "      <th>absorbance3</th>\n",
              "      <th>absorbance4</th>\n",
              "      <th>absorbance5</th>\n",
              "      <th>absorbance6</th>\n",
              "      <th>absorbance7</th>\n",
              "      <th>absorbance8</th>\n",
              "      <th>absorbance9</th>\n",
              "      <th>absorbance10</th>\n",
              "      <th>absorbance11</th>\n",
              "      <th>absorbance12</th>\n",
              "      <th>absorbance13</th>\n",
              "      <th>absorbance14</th>\n",
              "      <th>absorbance15</th>\n",
              "      <th>absorbance16</th>\n",
              "      <th>absorbance17</th>\n",
              "      <th>absorbance18</th>\n",
              "      <th>absorbance19</th>\n",
              "      <th>absorbance20</th>\n",
              "      <th>absorbance21</th>\n",
              "      <th>absorbance22</th>\n",
              "      <th>absorbance23</th>\n",
              "      <th>absorbance24</th>\n",
              "      <th>absorbance25</th>\n",
              "      <th>absorbance26</th>\n",
              "      <th>absorbance27</th>\n",
              "      <th>absorbance28</th>\n",
              "      <th>absorbance29</th>\n",
              "      <th>absorbance30</th>\n",
              "      <th>absorbance31</th>\n",
              "      <th>absorbance32</th>\n",
              "      <th>absorbance33</th>\n",
              "      <th>absorbance34</th>\n",
              "      <th>absorbance35</th>\n",
              "      <th>absorbance36</th>\n",
              "      <th>absorbance37</th>\n",
              "      <th>absorbance38</th>\n",
              "      <th>...</th>\n",
              "      <th>absorbance135</th>\n",
              "      <th>absorbance136</th>\n",
              "      <th>absorbance137</th>\n",
              "      <th>absorbance138</th>\n",
              "      <th>absorbance139</th>\n",
              "      <th>absorbance140</th>\n",
              "      <th>absorbance141</th>\n",
              "      <th>absorbance142</th>\n",
              "      <th>absorbance143</th>\n",
              "      <th>absorbance144</th>\n",
              "      <th>absorbance145</th>\n",
              "      <th>absorbance146</th>\n",
              "      <th>absorbance147</th>\n",
              "      <th>absorbance148</th>\n",
              "      <th>absorbance149</th>\n",
              "      <th>absorbance150</th>\n",
              "      <th>absorbance151</th>\n",
              "      <th>absorbance152</th>\n",
              "      <th>absorbance153</th>\n",
              "      <th>absorbance154</th>\n",
              "      <th>absorbance155</th>\n",
              "      <th>absorbance156</th>\n",
              "      <th>absorbance157</th>\n",
              "      <th>absorbance158</th>\n",
              "      <th>absorbance159</th>\n",
              "      <th>absorbance160</th>\n",
              "      <th>absorbance161</th>\n",
              "      <th>absorbance162</th>\n",
              "      <th>absorbance163</th>\n",
              "      <th>absorbance164</th>\n",
              "      <th>absorbance165</th>\n",
              "      <th>absorbance166</th>\n",
              "      <th>absorbance167</th>\n",
              "      <th>absorbance168</th>\n",
              "      <th>absorbance169</th>\n",
              "      <th>donation_id</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>cholesterol_ldl_value</th>\n",
              "      <th>cholesterol_ldl_human</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "      <td>32520.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10247.987085</td>\n",
              "      <td>0.520451</td>\n",
              "      <td>0.522427</td>\n",
              "      <td>0.525972</td>\n",
              "      <td>0.530680</td>\n",
              "      <td>0.536854</td>\n",
              "      <td>0.543551</td>\n",
              "      <td>0.549648</td>\n",
              "      <td>0.555232</td>\n",
              "      <td>0.563119</td>\n",
              "      <td>0.574407</td>\n",
              "      <td>0.587313</td>\n",
              "      <td>0.598591</td>\n",
              "      <td>0.605160</td>\n",
              "      <td>0.608182</td>\n",
              "      <td>0.609431</td>\n",
              "      <td>0.609150</td>\n",
              "      <td>0.607543</td>\n",
              "      <td>0.605090</td>\n",
              "      <td>0.602129</td>\n",
              "      <td>0.598775</td>\n",
              "      <td>0.595773</td>\n",
              "      <td>0.592707</td>\n",
              "      <td>0.589487</td>\n",
              "      <td>0.585683</td>\n",
              "      <td>0.582415</td>\n",
              "      <td>0.579220</td>\n",
              "      <td>0.576781</td>\n",
              "      <td>0.574689</td>\n",
              "      <td>0.572943</td>\n",
              "      <td>0.571480</td>\n",
              "      <td>0.570644</td>\n",
              "      <td>0.570247</td>\n",
              "      <td>0.570480</td>\n",
              "      <td>0.571400</td>\n",
              "      <td>0.572933</td>\n",
              "      <td>0.575169</td>\n",
              "      <td>0.577869</td>\n",
              "      <td>0.581283</td>\n",
              "      <td>0.585061</td>\n",
              "      <td>...</td>\n",
              "      <td>1.497814</td>\n",
              "      <td>1.485553</td>\n",
              "      <td>1.474109</td>\n",
              "      <td>1.463112</td>\n",
              "      <td>1.450626</td>\n",
              "      <td>1.439371</td>\n",
              "      <td>1.428135</td>\n",
              "      <td>1.417230</td>\n",
              "      <td>1.406798</td>\n",
              "      <td>1.398556</td>\n",
              "      <td>1.385953</td>\n",
              "      <td>1.377019</td>\n",
              "      <td>1.368533</td>\n",
              "      <td>1.360171</td>\n",
              "      <td>1.351819</td>\n",
              "      <td>1.344645</td>\n",
              "      <td>1.337181</td>\n",
              "      <td>1.330049</td>\n",
              "      <td>1.323455</td>\n",
              "      <td>1.316835</td>\n",
              "      <td>1.311906</td>\n",
              "      <td>1.307739</td>\n",
              "      <td>1.304195</td>\n",
              "      <td>1.301982</td>\n",
              "      <td>1.301178</td>\n",
              "      <td>1.300802</td>\n",
              "      <td>1.300394</td>\n",
              "      <td>1.299197</td>\n",
              "      <td>1.295539</td>\n",
              "      <td>1.289453</td>\n",
              "      <td>1.282270</td>\n",
              "      <td>1.275940</td>\n",
              "      <td>1.272953</td>\n",
              "      <td>1.287608</td>\n",
              "      <td>1.275556</td>\n",
              "      <td>6927.533210</td>\n",
              "      <td>42.111418</td>\n",
              "      <td>39.222955</td>\n",
              "      <td>111.436592</td>\n",
              "      <td>1.485240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7217.494367</td>\n",
              "      <td>0.041112</td>\n",
              "      <td>0.040721</td>\n",
              "      <td>0.040812</td>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.040851</td>\n",
              "      <td>0.041212</td>\n",
              "      <td>0.041108</td>\n",
              "      <td>0.041028</td>\n",
              "      <td>0.040799</td>\n",
              "      <td>0.040583</td>\n",
              "      <td>0.040467</td>\n",
              "      <td>0.040440</td>\n",
              "      <td>0.040371</td>\n",
              "      <td>0.040357</td>\n",
              "      <td>0.040423</td>\n",
              "      <td>0.040384</td>\n",
              "      <td>0.040286</td>\n",
              "      <td>0.040235</td>\n",
              "      <td>0.040161</td>\n",
              "      <td>0.040257</td>\n",
              "      <td>0.040208</td>\n",
              "      <td>0.040203</td>\n",
              "      <td>0.040219</td>\n",
              "      <td>0.040330</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.040505</td>\n",
              "      <td>0.040565</td>\n",
              "      <td>0.040594</td>\n",
              "      <td>0.040617</td>\n",
              "      <td>0.040604</td>\n",
              "      <td>0.040585</td>\n",
              "      <td>0.040536</td>\n",
              "      <td>0.040548</td>\n",
              "      <td>0.040518</td>\n",
              "      <td>0.040482</td>\n",
              "      <td>0.040474</td>\n",
              "      <td>0.040484</td>\n",
              "      <td>0.040568</td>\n",
              "      <td>0.040562</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092871</td>\n",
              "      <td>0.091442</td>\n",
              "      <td>0.090024</td>\n",
              "      <td>0.088669</td>\n",
              "      <td>0.087008</td>\n",
              "      <td>0.085677</td>\n",
              "      <td>0.084387</td>\n",
              "      <td>0.083439</td>\n",
              "      <td>0.082445</td>\n",
              "      <td>0.081613</td>\n",
              "      <td>0.080247</td>\n",
              "      <td>0.079475</td>\n",
              "      <td>0.078764</td>\n",
              "      <td>0.078134</td>\n",
              "      <td>0.077412</td>\n",
              "      <td>0.076854</td>\n",
              "      <td>0.076236</td>\n",
              "      <td>0.075665</td>\n",
              "      <td>0.075127</td>\n",
              "      <td>0.074675</td>\n",
              "      <td>0.074371</td>\n",
              "      <td>0.074165</td>\n",
              "      <td>0.074055</td>\n",
              "      <td>0.074165</td>\n",
              "      <td>0.074513</td>\n",
              "      <td>0.075227</td>\n",
              "      <td>0.076246</td>\n",
              "      <td>0.077813</td>\n",
              "      <td>0.080530</td>\n",
              "      <td>0.084704</td>\n",
              "      <td>0.090256</td>\n",
              "      <td>0.096075</td>\n",
              "      <td>0.100996</td>\n",
              "      <td>0.108040</td>\n",
              "      <td>0.107367</td>\n",
              "      <td>3092.146553</td>\n",
              "      <td>3.516987</td>\n",
              "      <td>8.996599</td>\n",
              "      <td>44.266598</td>\n",
              "      <td>1.030351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.392912</td>\n",
              "      <td>0.394812</td>\n",
              "      <td>0.400689</td>\n",
              "      <td>0.403960</td>\n",
              "      <td>0.408725</td>\n",
              "      <td>0.413678</td>\n",
              "      <td>0.419136</td>\n",
              "      <td>0.426281</td>\n",
              "      <td>0.436464</td>\n",
              "      <td>0.448900</td>\n",
              "      <td>0.461060</td>\n",
              "      <td>0.472540</td>\n",
              "      <td>0.479179</td>\n",
              "      <td>0.481304</td>\n",
              "      <td>0.483719</td>\n",
              "      <td>0.483216</td>\n",
              "      <td>0.481971</td>\n",
              "      <td>0.480212</td>\n",
              "      <td>0.477067</td>\n",
              "      <td>0.473347</td>\n",
              "      <td>0.470453</td>\n",
              "      <td>0.467312</td>\n",
              "      <td>0.464336</td>\n",
              "      <td>0.460893</td>\n",
              "      <td>0.457083</td>\n",
              "      <td>0.453718</td>\n",
              "      <td>0.452251</td>\n",
              "      <td>0.450437</td>\n",
              "      <td>0.448239</td>\n",
              "      <td>0.447033</td>\n",
              "      <td>0.446642</td>\n",
              "      <td>0.446144</td>\n",
              "      <td>0.446081</td>\n",
              "      <td>0.447483</td>\n",
              "      <td>0.448803</td>\n",
              "      <td>0.451550</td>\n",
              "      <td>0.454424</td>\n",
              "      <td>0.457708</td>\n",
              "      <td>0.461049</td>\n",
              "      <td>...</td>\n",
              "      <td>1.183231</td>\n",
              "      <td>1.176505</td>\n",
              "      <td>1.165242</td>\n",
              "      <td>1.156129</td>\n",
              "      <td>1.144757</td>\n",
              "      <td>1.137224</td>\n",
              "      <td>1.124663</td>\n",
              "      <td>1.118230</td>\n",
              "      <td>1.112741</td>\n",
              "      <td>1.102217</td>\n",
              "      <td>1.095277</td>\n",
              "      <td>1.086852</td>\n",
              "      <td>1.077081</td>\n",
              "      <td>1.070212</td>\n",
              "      <td>1.065788</td>\n",
              "      <td>1.059473</td>\n",
              "      <td>1.049844</td>\n",
              "      <td>1.047231</td>\n",
              "      <td>1.040516</td>\n",
              "      <td>1.033820</td>\n",
              "      <td>1.027625</td>\n",
              "      <td>1.025531</td>\n",
              "      <td>1.022200</td>\n",
              "      <td>1.023248</td>\n",
              "      <td>1.020356</td>\n",
              "      <td>1.021583</td>\n",
              "      <td>1.017810</td>\n",
              "      <td>1.014555</td>\n",
              "      <td>1.010671</td>\n",
              "      <td>0.999792</td>\n",
              "      <td>0.988702</td>\n",
              "      <td>0.960985</td>\n",
              "      <td>0.941157</td>\n",
              "      <td>0.922162</td>\n",
              "      <td>0.909459</td>\n",
              "      <td>1974.000000</td>\n",
              "      <td>28.010000</td>\n",
              "      <td>15.890000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4064.750000</td>\n",
              "      <td>0.491860</td>\n",
              "      <td>0.494169</td>\n",
              "      <td>0.497748</td>\n",
              "      <td>0.502383</td>\n",
              "      <td>0.508288</td>\n",
              "      <td>0.514470</td>\n",
              "      <td>0.520772</td>\n",
              "      <td>0.526496</td>\n",
              "      <td>0.535008</td>\n",
              "      <td>0.547020</td>\n",
              "      <td>0.560224</td>\n",
              "      <td>0.571859</td>\n",
              "      <td>0.578321</td>\n",
              "      <td>0.581321</td>\n",
              "      <td>0.582474</td>\n",
              "      <td>0.582236</td>\n",
              "      <td>0.580808</td>\n",
              "      <td>0.578452</td>\n",
              "      <td>0.575528</td>\n",
              "      <td>0.571945</td>\n",
              "      <td>0.568959</td>\n",
              "      <td>0.565812</td>\n",
              "      <td>0.562522</td>\n",
              "      <td>0.558460</td>\n",
              "      <td>0.555051</td>\n",
              "      <td>0.551830</td>\n",
              "      <td>0.549289</td>\n",
              "      <td>0.547135</td>\n",
              "      <td>0.545315</td>\n",
              "      <td>0.543820</td>\n",
              "      <td>0.543043</td>\n",
              "      <td>0.542637</td>\n",
              "      <td>0.542892</td>\n",
              "      <td>0.543817</td>\n",
              "      <td>0.545465</td>\n",
              "      <td>0.547784</td>\n",
              "      <td>0.550492</td>\n",
              "      <td>0.553965</td>\n",
              "      <td>0.557821</td>\n",
              "      <td>...</td>\n",
              "      <td>1.438010</td>\n",
              "      <td>1.427328</td>\n",
              "      <td>1.417247</td>\n",
              "      <td>1.407267</td>\n",
              "      <td>1.395763</td>\n",
              "      <td>1.385219</td>\n",
              "      <td>1.374617</td>\n",
              "      <td>1.364290</td>\n",
              "      <td>1.354204</td>\n",
              "      <td>1.346824</td>\n",
              "      <td>1.335189</td>\n",
              "      <td>1.326460</td>\n",
              "      <td>1.318812</td>\n",
              "      <td>1.310854</td>\n",
              "      <td>1.303209</td>\n",
              "      <td>1.296437</td>\n",
              "      <td>1.289252</td>\n",
              "      <td>1.283134</td>\n",
              "      <td>1.276608</td>\n",
              "      <td>1.270620</td>\n",
              "      <td>1.265566</td>\n",
              "      <td>1.261691</td>\n",
              "      <td>1.258683</td>\n",
              "      <td>1.256083</td>\n",
              "      <td>1.255057</td>\n",
              "      <td>1.253884</td>\n",
              "      <td>1.252200</td>\n",
              "      <td>1.249600</td>\n",
              "      <td>1.244411</td>\n",
              "      <td>1.236482</td>\n",
              "      <td>1.226619</td>\n",
              "      <td>1.216275</td>\n",
              "      <td>1.209598</td>\n",
              "      <td>1.217952</td>\n",
              "      <td>1.206609</td>\n",
              "      <td>4150.000000</td>\n",
              "      <td>39.430000</td>\n",
              "      <td>33.500000</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8219.500000</td>\n",
              "      <td>0.517527</td>\n",
              "      <td>0.519885</td>\n",
              "      <td>0.523621</td>\n",
              "      <td>0.528590</td>\n",
              "      <td>0.534754</td>\n",
              "      <td>0.541595</td>\n",
              "      <td>0.547768</td>\n",
              "      <td>0.553486</td>\n",
              "      <td>0.561304</td>\n",
              "      <td>0.572617</td>\n",
              "      <td>0.585552</td>\n",
              "      <td>0.596953</td>\n",
              "      <td>0.603590</td>\n",
              "      <td>0.606889</td>\n",
              "      <td>0.608253</td>\n",
              "      <td>0.607971</td>\n",
              "      <td>0.606372</td>\n",
              "      <td>0.603929</td>\n",
              "      <td>0.600913</td>\n",
              "      <td>0.597421</td>\n",
              "      <td>0.594272</td>\n",
              "      <td>0.591045</td>\n",
              "      <td>0.587712</td>\n",
              "      <td>0.583978</td>\n",
              "      <td>0.580637</td>\n",
              "      <td>0.577243</td>\n",
              "      <td>0.574890</td>\n",
              "      <td>0.572737</td>\n",
              "      <td>0.570928</td>\n",
              "      <td>0.569500</td>\n",
              "      <td>0.568608</td>\n",
              "      <td>0.568228</td>\n",
              "      <td>0.568291</td>\n",
              "      <td>0.569071</td>\n",
              "      <td>0.570413</td>\n",
              "      <td>0.572692</td>\n",
              "      <td>0.575350</td>\n",
              "      <td>0.578781</td>\n",
              "      <td>0.582645</td>\n",
              "      <td>...</td>\n",
              "      <td>1.508629</td>\n",
              "      <td>1.495830</td>\n",
              "      <td>1.483630</td>\n",
              "      <td>1.472217</td>\n",
              "      <td>1.459012</td>\n",
              "      <td>1.447017</td>\n",
              "      <td>1.434808</td>\n",
              "      <td>1.423413</td>\n",
              "      <td>1.412032</td>\n",
              "      <td>1.403390</td>\n",
              "      <td>1.390133</td>\n",
              "      <td>1.380523</td>\n",
              "      <td>1.371662</td>\n",
              "      <td>1.362995</td>\n",
              "      <td>1.354108</td>\n",
              "      <td>1.346538</td>\n",
              "      <td>1.339033</td>\n",
              "      <td>1.332047</td>\n",
              "      <td>1.325562</td>\n",
              "      <td>1.318705</td>\n",
              "      <td>1.313679</td>\n",
              "      <td>1.309108</td>\n",
              "      <td>1.305783</td>\n",
              "      <td>1.303523</td>\n",
              "      <td>1.302699</td>\n",
              "      <td>1.302412</td>\n",
              "      <td>1.301974</td>\n",
              "      <td>1.300699</td>\n",
              "      <td>1.296696</td>\n",
              "      <td>1.290281</td>\n",
              "      <td>1.282202</td>\n",
              "      <td>1.274101</td>\n",
              "      <td>1.270363</td>\n",
              "      <td>1.284322</td>\n",
              "      <td>1.270917</td>\n",
              "      <td>7086.500000</td>\n",
              "      <td>41.770000</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>109.850000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16469.250000</td>\n",
              "      <td>0.547231</td>\n",
              "      <td>0.548672</td>\n",
              "      <td>0.552523</td>\n",
              "      <td>0.556908</td>\n",
              "      <td>0.563277</td>\n",
              "      <td>0.570327</td>\n",
              "      <td>0.576505</td>\n",
              "      <td>0.582081</td>\n",
              "      <td>0.589770</td>\n",
              "      <td>0.601252</td>\n",
              "      <td>0.614298</td>\n",
              "      <td>0.625814</td>\n",
              "      <td>0.632132</td>\n",
              "      <td>0.635091</td>\n",
              "      <td>0.636604</td>\n",
              "      <td>0.636595</td>\n",
              "      <td>0.634891</td>\n",
              "      <td>0.632431</td>\n",
              "      <td>0.629257</td>\n",
              "      <td>0.625971</td>\n",
              "      <td>0.622748</td>\n",
              "      <td>0.619450</td>\n",
              "      <td>0.616193</td>\n",
              "      <td>0.612664</td>\n",
              "      <td>0.609437</td>\n",
              "      <td>0.606294</td>\n",
              "      <td>0.604061</td>\n",
              "      <td>0.602109</td>\n",
              "      <td>0.600574</td>\n",
              "      <td>0.599218</td>\n",
              "      <td>0.598550</td>\n",
              "      <td>0.598366</td>\n",
              "      <td>0.598748</td>\n",
              "      <td>0.599672</td>\n",
              "      <td>0.601094</td>\n",
              "      <td>0.603354</td>\n",
              "      <td>0.606094</td>\n",
              "      <td>0.609853</td>\n",
              "      <td>0.613530</td>\n",
              "      <td>...</td>\n",
              "      <td>1.562273</td>\n",
              "      <td>1.548804</td>\n",
              "      <td>1.535988</td>\n",
              "      <td>1.523693</td>\n",
              "      <td>1.509968</td>\n",
              "      <td>1.497193</td>\n",
              "      <td>1.484683</td>\n",
              "      <td>1.473115</td>\n",
              "      <td>1.461577</td>\n",
              "      <td>1.452842</td>\n",
              "      <td>1.438945</td>\n",
              "      <td>1.428922</td>\n",
              "      <td>1.420075</td>\n",
              "      <td>1.410939</td>\n",
              "      <td>1.401925</td>\n",
              "      <td>1.394401</td>\n",
              "      <td>1.386527</td>\n",
              "      <td>1.378951</td>\n",
              "      <td>1.371893</td>\n",
              "      <td>1.364892</td>\n",
              "      <td>1.359990</td>\n",
              "      <td>1.355486</td>\n",
              "      <td>1.351519</td>\n",
              "      <td>1.349453</td>\n",
              "      <td>1.348723</td>\n",
              "      <td>1.348609</td>\n",
              "      <td>1.348757</td>\n",
              "      <td>1.347706</td>\n",
              "      <td>1.345494</td>\n",
              "      <td>1.342177</td>\n",
              "      <td>1.338315</td>\n",
              "      <td>1.335099</td>\n",
              "      <td>1.334912</td>\n",
              "      <td>1.354563</td>\n",
              "      <td>1.343021</td>\n",
              "      <td>9622.000000</td>\n",
              "      <td>44.460000</td>\n",
              "      <td>45.160000</td>\n",
              "      <td>136.600000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>24599.000000</td>\n",
              "      <td>0.712261</td>\n",
              "      <td>0.713953</td>\n",
              "      <td>0.714301</td>\n",
              "      <td>0.717904</td>\n",
              "      <td>0.721125</td>\n",
              "      <td>0.735604</td>\n",
              "      <td>0.742404</td>\n",
              "      <td>0.747143</td>\n",
              "      <td>0.750705</td>\n",
              "      <td>0.760174</td>\n",
              "      <td>0.772678</td>\n",
              "      <td>0.780692</td>\n",
              "      <td>0.789328</td>\n",
              "      <td>0.793191</td>\n",
              "      <td>0.792140</td>\n",
              "      <td>0.789813</td>\n",
              "      <td>0.788963</td>\n",
              "      <td>0.785027</td>\n",
              "      <td>0.783663</td>\n",
              "      <td>0.780449</td>\n",
              "      <td>0.777302</td>\n",
              "      <td>0.777308</td>\n",
              "      <td>0.771199</td>\n",
              "      <td>0.767564</td>\n",
              "      <td>0.764990</td>\n",
              "      <td>0.761299</td>\n",
              "      <td>0.757902</td>\n",
              "      <td>0.757501</td>\n",
              "      <td>0.754544</td>\n",
              "      <td>0.752520</td>\n",
              "      <td>0.750846</td>\n",
              "      <td>0.750211</td>\n",
              "      <td>0.750562</td>\n",
              "      <td>0.752338</td>\n",
              "      <td>0.752356</td>\n",
              "      <td>0.752844</td>\n",
              "      <td>0.757105</td>\n",
              "      <td>0.758228</td>\n",
              "      <td>0.762346</td>\n",
              "      <td>...</td>\n",
              "      <td>1.810597</td>\n",
              "      <td>1.792020</td>\n",
              "      <td>1.795979</td>\n",
              "      <td>1.760903</td>\n",
              "      <td>1.746026</td>\n",
              "      <td>1.732596</td>\n",
              "      <td>1.722528</td>\n",
              "      <td>1.701110</td>\n",
              "      <td>1.701727</td>\n",
              "      <td>1.689573</td>\n",
              "      <td>1.675222</td>\n",
              "      <td>1.652882</td>\n",
              "      <td>1.638239</td>\n",
              "      <td>1.640744</td>\n",
              "      <td>1.622442</td>\n",
              "      <td>1.621058</td>\n",
              "      <td>1.591396</td>\n",
              "      <td>1.598650</td>\n",
              "      <td>1.579202</td>\n",
              "      <td>1.586529</td>\n",
              "      <td>1.563348</td>\n",
              "      <td>1.564905</td>\n",
              "      <td>1.553456</td>\n",
              "      <td>1.568073</td>\n",
              "      <td>1.555082</td>\n",
              "      <td>1.572439</td>\n",
              "      <td>1.570720</td>\n",
              "      <td>1.576210</td>\n",
              "      <td>1.578341</td>\n",
              "      <td>1.599242</td>\n",
              "      <td>1.618288</td>\n",
              "      <td>1.675462</td>\n",
              "      <td>1.650094</td>\n",
              "      <td>1.720367</td>\n",
              "      <td>1.753565</td>\n",
              "      <td>11966.000000</td>\n",
              "      <td>53.680000</td>\n",
              "      <td>69.110000</td>\n",
              "      <td>310.800000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 176 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1e97eae-2b8b-4658-a992-1d45b8b4bec6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1e97eae-2b8b-4658-a992-1d45b8b4bec6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1e97eae-2b8b-4658-a992-1d45b8b4bec6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Unnamed: 0   absorbance0  ...  cholesterol_ldl_value  cholesterol_ldl_human\n",
              "count  32520.000000  32520.000000  ...           32520.000000           32520.000000\n",
              "mean   10247.987085      0.520451  ...             111.436592               1.485240\n",
              "std     7217.494367      0.041112  ...              44.266598               1.030351\n",
              "min        0.000000      0.392912  ...               5.300000               0.000000\n",
              "25%     4064.750000      0.491860  ...              81.250000               1.000000\n",
              "50%     8219.500000      0.517527  ...             109.850000               1.000000\n",
              "75%    16469.250000      0.547231  ...             136.600000               3.000000\n",
              "max    24599.000000      0.712261  ...             310.800000               3.000000\n",
              "\n",
              "[8 rows x 176 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_agg.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YTJL576ZmB3U"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout,Embedding, Flatten,LayerNormalization\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "import keras.optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld,mse\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tyAOeKvNmIFk"
      },
      "outputs": [],
      "source": [
        "X_columns=list(df_agg.columns[1:-5])\n",
        "X_columns.append(\"temperature\")\n",
        "y_columns=df_agg.columns[-1] # the category is at the end of columns\n",
        "X_=df_agg[X_columns]\n",
        "y_=df_agg[y_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x-ZQDORU8dSB"
      },
      "outputs": [],
      "source": [
        "y_.replace(3,2, inplace=True) # the generated file contains  0,1,3 as the category label :-( "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ktI0xxn_8_1c"
      },
      "outputs": [],
      "source": [
        "#y_.replace(2,0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "T1yh_hqpqEt4"
      },
      "outputs": [],
      "source": [
        "y_=np.array(y_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Mstvf1lXqSEe"
      },
      "outputs": [],
      "source": [
        "y_=y_.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ugaWW0KOq90O",
        "outputId": "2cd56e6c-bd2c-4946-e7c7-ea181a7b0d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cholesterol_ldl_human'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "y_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ__bM5BpIaE",
        "outputId": "178e6386-2155-4adc-f888-f5d67e081828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]\n",
            " [31.9]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_columns=df_agg.columns[1:-5]\n",
        "y_columns=df_agg.columns[-1] # the category is at the end of columns\n",
        "X_=df_agg[X_columns]\n",
        "y_=df_agg[y_columns]\n",
        "\n",
        "y_.replace(3,2, inplace=True) # the generated file contains  0,1,3 as the category label :-( \n",
        "\n",
        "y_=np.array(y_)\n",
        "y_=y_.reshape(-1,1)\n",
        "\n",
        "\n",
        "\n",
        "__X_SCALER__=\"normal\"\n",
        "\n",
        "__DNN_MODE__=\"regression\"\n",
        "\n",
        "__Y_SCALER__=\"minmax\"\n",
        "\n",
        "if __DNN_MODE__==\"regression\":\n",
        "    y_columns=df_agg.columns[-2] # the category is at the  -2  column\n",
        "    y_=df_agg[y_columns]\n",
        "    y_=np.array(y_)\n",
        "    y_=y_.reshape(-1,1)\n",
        "\n",
        "\n",
        "elif __DNN_MODE__==\"classification\":\n",
        "    y_columns=df_agg.columns[-1] # the category is at the end of columns\n",
        "    y_=df_agg[y_columns]\n",
        "    y_.replace(3,2, inplace=True) # the generated file contains  0,1,3 as the category label :-( \n",
        "    y_=np.array(y_)\n",
        "    y_=y_.reshape(-1,1)\n",
        "\n",
        "y=y_\n",
        "print(y[0:10])\n",
        "\n",
        "if __X_SCALER__==\"normal\":\n",
        "    X_normalizer = StandardScaler() \n",
        "    X=X_normalizer.fit_transform(X_)\n",
        "\n",
        "if __Y_SCALER__==\"normal\":\n",
        "    y_normalizer = StandardScaler() \n",
        "    y=y_normalizer.fit_transform(y_,)\n",
        "    print(f\"Itt: {y}\")\n",
        "\n",
        "if __X_SCALER__==\"minmax\":\n",
        "    X_minmax = MinMaxScaler() \n",
        "    X=X_minmax.fit_transform(X_)\n",
        "\n",
        "if __Y_SCALER__==\"minmax\":\n",
        "    y_minmax = MinMaxScaler() \n",
        "    y=y_minmax.fit_transform(y_)\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EOpMpaVeFrrX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "39NoNiEM-dHG",
        "outputId": "7ce2165e-d8e1-4310-ba77-facf0c595c44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport wandb\\nfrom wandb.keras import WandbCallback\\n\\nwandb.init(config={\"hyper\": \"parameter\"})\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "'''\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.init(config={\"hyper\": \"parameter\"})\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2f2U85aQmiaZ"
      },
      "outputs": [],
      "source": [
        "def blood_model_2():\n",
        "    #clear_session()\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    input_len=170\n",
        "\n",
        "    print(input_len)\n",
        "    output_size=24\n",
        "    drop_frac0=0.0 \n",
        "    drop_frac1=0.0\n",
        "\n",
        "\n",
        "\n",
        "    input1=Input(shape=(input_len,))\n",
        "\n",
        "    #flatt=Flatten()(lstm1)\n",
        "\n",
        "    non=42\n",
        "    #initializer = tf.keras.initializers.LecunNormal()\n",
        "    #initializer=tf.keras.initializers.LecunUniform()\n",
        "    #initializer=tf.keras.initializers.HeUniform(    seed=None)\n",
        "    #initializer= tf.keras.initializers.RandomNormal(    mean=3.0, stddev=0.05, seed=None)\n",
        "\n",
        "    initializer=\"HeNormal\"\n",
        "    d1=Dense(1000,activation=\"sigmoid\",kernel_initializer=initializer)(input1)\n",
        "    d1=Dense(100,activation=\"sigmoid\",kernel_initializer=initializer)(d1)\n",
        "    #d1=Dense(100,activation=\"selu\",kernel_initializer=initializer)(d1)\n",
        "\n",
        "\n",
        "    #softmax\n",
        "    pred=Dense(1,activation=\"sigmoid\",)(d1)\n",
        "\n",
        "    \n",
        "    \n",
        "    model = Model(inputs=input1, outputs=pred)\n",
        "\n",
        "    opt = tf.keras.optimizers.Adamax(learning_rate=0.001)\n",
        "\n",
        "\n",
        "    lossfn = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "\n",
        "    model.compile(loss=\"CategoricalCrossentropy\",\n",
        "        optimizer=opt,\n",
        "        metrics=[\"Accuracy\"])\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LtOGK6OIZ9Pu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndb5XDN9nwsC",
        "outputId": "b822a629-08d6-49a8-9c12-79bb44759876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 12.7 MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.1-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 65.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=2aa015b19653db401c9e26f658deb938a79250bd293a8da9ae08c8c86c7c3dff\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=6ac82aa552775513bd5d9686c4ff2647cf38e63d0560630793118ee9ae1d5416\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.1 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "3Rn8vSnroH4R",
        "outputId": "a85917af-b940-4699-b363-137770ab5e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msipoczlaszlo\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/sipoczlaszlo/BM_Norm_5/runs/6w26b7p2\" target=\"_blank\">solar-microwave-20</a></strong> to <a href=\"https://wandb.ai/sipoczlaszlo/BM_Norm_5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f2b88421650>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sipoczlaszlo/BM_Norm_5/runs/6w26b7p2?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.init(project=\"BM_Norm_5\", entity=\"sipoczlaszlo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "f3cQpWHeJ4IJ"
      },
      "outputs": [],
      "source": [
        "def blood_model_regression():\n",
        "    #clear_session()\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    input_len=170\n",
        "\n",
        "    print(input_len)\n",
        "    output_size=24\n",
        "    drop_frac0=0.00000 \n",
        "    drop_frac1=0.0\n",
        "\n",
        "\n",
        "\n",
        "    input1=Input(shape=(input_len,))\n",
        "\n",
        "    #flatt=Flatten()(lstm1)\n",
        "\n",
        "    non=42\n",
        "    #initializer = tf.keras.initializers.LecunNormal()\n",
        "    #initializer=tf.keras.initializers.LecunUniform()\n",
        "    #initializer=tf.keras.initializers.HeUniform(    seed=None)\n",
        "    #initializer= tf.keras.initializers.RandomNormal(    mean=3.0, stddev=0.05, seed=None)\n",
        "    # 5512 relu  256 relu  \n",
        "    initializer=\"HeNormal\"\n",
        "    initializer2=\"GlorotNormal\"\n",
        "    initializer = tf.keras.initializers.HeNormal()\n",
        "    d1=Dense(12512,activation=\"relu\",kernel_initializer=initializer)(input1)\n",
        "    d1=Dropout(drop_frac0)(d1)\n",
        "    \n",
        "    d1=Dense(2156,activation=\"relu\",kernel_initializer=initializer)(d1)\n",
        "    d1=Dense(216,activation=\"relu\",kernel_initializer=initializer)(d1)\n",
        "    \n",
        "    #d1=Dropout(drop_frac1)(d1)\n",
        "    #d1=Dense(128,activation=\"tanh\",kernel_initializer=initializer2)(d1)\n",
        "    # d1=Dropout(drop_frac1)(d1) \n",
        "\n",
        "    #softmax\n",
        "    pred=Dense(1, kernel_initializer=initializer)(d1)\n",
        "\n",
        "    \n",
        "    \n",
        "    model = Model(inputs=input1, outputs=pred)\n",
        "\n",
        "    opt = tf.keras.optimizers.SGD(learning_rate=0.0000001)\n",
        "\n",
        "\n",
        "    lossfn = tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "\n",
        "    model.compile(loss=\"MSE\",\n",
        "        optimizer=opt,\n",
        "        metrics=[\"MSE\"])\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rsAoivPNaBOU",
        "outputId": "365bdc80-0cc2-4d6a-e1e2-2564fd5590f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'regression'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "__DNN_MODE__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DEVcX9Z5mwnz"
      },
      "outputs": [],
      "source": [
        "if __DNN_MODE__==\"classification\":\n",
        "    model_name=\"classification_\"\n",
        "    def scheduler(epoch, lr):\n",
        "        return 0.001\n",
        "\n",
        "    callback_LR = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "    callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_{val_loss:.5f}_{loss:.5f}_.hdf5\", monitor='val_loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zSCDNBu4aH9P"
      },
      "outputs": [],
      "source": [
        "if __DNN_MODE__==\"regression\":\n",
        "    model_name=\"regression_\"\n",
        "    def scheduler(epoch, lr):\n",
        "       #return 0.00003\n",
        "        \n",
        "        maxx=0.000003\n",
        "        minn=0.0001\n",
        "        frekvency=50\n",
        "        o=(epoch % frekvency)/frekvency * (maxx-minn)+minn\n",
        "        return o\n",
        "\n",
        "        \n",
        "        if epoch<50:\n",
        "            return 0.001\n",
        "        elif epoch <100:\n",
        "            return 0.001\n",
        "        elif epoch <1200:\n",
        "            return 0.0001\n",
        "        return 0.001    \n",
        "\n",
        "\n",
        "    callback_LR = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "    callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_{loss:.5f}_{val_loss:.5f}_.hdf5\", monitor='val_loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yakOYRb_m07P"
      },
      "outputs": [],
      "source": [
        "if __DNN_MODE__==\"classification\":\n",
        "    new_model_2=blood_model_2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IM-jEkwbG2A",
        "outputId": "512564c5-77a2-414e-8b1a-3a6b06419fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170\n"
          ]
        }
      ],
      "source": [
        "if __DNN_MODE__==\"regression\":\n",
        "    new_model_2=blood_model_regression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "9-rSra7K3wVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962b7607-6729-4ea7-d4ed-6ac512fff7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '*.hdf5': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm *.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Us0FJewhDKc",
        "outputId": "953760be-13ce-47c4-afa5-14c27ced8308"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.84291107,  0.87084623,  0.85384503, ...,  0.88592384,\n",
              "         0.69807174,  0.62136917],\n",
              "       [ 0.85890338,  0.93575649,  0.79650173, ...,  0.59921558,\n",
              "         0.36804195,  0.59178345],\n",
              "       [ 1.02517371,  0.98026626,  1.03813112, ...,  0.75418405,\n",
              "         0.59318911,  0.72327235],\n",
              "       ...,\n",
              "       [-0.3165878 , -0.32159651, -0.35542714, ...,  0.4074519 ,\n",
              "         0.42681638,  0.83543855],\n",
              "       [-0.39189285, -0.2486709 , -0.27101785, ...,  0.35061772,\n",
              "         0.14746353,  0.31313052],\n",
              "       [-0.35342492, -0.3093902 , -0.3257258 , ...,  0.91233697,\n",
              "         0.57188824,  0.7372212 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.model_selection import train_test_split\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "DJR2QurIg3CI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHWVim-0vPxT",
        "outputId": "a2153bce-42b8-4696-e755-8c74b1c8e923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 170)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12512)             2139552   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12512)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2156)              26978028  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 216)               465912    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 217       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,583,709\n",
            "Trainable params: 29,583,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0707 - MSE: 0.0707\n",
            "Epoch 00001: val_loss improved from inf to 0.02369, saving model to regression__0.07072_0.02369_.hdf5\n",
            "4878/4878 [==============================] - 1292s 265ms/step - loss: 0.0707 - MSE: 0.0707 - val_loss: 0.0237 - val_MSE: 0.0237 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0247 - MSE: 0.0247\n",
            "Epoch 00002: val_loss improved from 0.02369 to 0.01915, saving model to regression__0.02471_0.01915_.hdf5\n",
            "4878/4878 [==============================] - 1479s 303ms/step - loss: 0.0247 - MSE: 0.0247 - val_loss: 0.0191 - val_MSE: 0.0191 - lr: 9.8060e-05\n",
            "Epoch 3/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0196 - MSE: 0.0196\n",
            "Epoch 00003: val_loss improved from 0.01915 to 0.01851, saving model to regression__0.01956_0.01851_.hdf5\n",
            "4878/4878 [==============================] - 1482s 304ms/step - loss: 0.0196 - MSE: 0.0196 - val_loss: 0.0185 - val_MSE: 0.0185 - lr: 9.6120e-05\n",
            "Epoch 4/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0164 - MSE: 0.0164\n",
            "Epoch 00004: val_loss improved from 0.01851 to 0.01605, saving model to regression__0.01639_0.01605_.hdf5\n",
            "4878/4878 [==============================] - 1451s 297ms/step - loss: 0.0164 - MSE: 0.0164 - val_loss: 0.0161 - val_MSE: 0.0161 - lr: 9.4180e-05\n",
            "Epoch 5/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0145 - MSE: 0.0145\n",
            "Epoch 00005: val_loss improved from 0.01605 to 0.01395, saving model to regression__0.01447_0.01395_.hdf5\n",
            "4878/4878 [==============================] - 1428s 293ms/step - loss: 0.0145 - MSE: 0.0145 - val_loss: 0.0139 - val_MSE: 0.0139 - lr: 9.2240e-05\n",
            "Epoch 6/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0130 - MSE: 0.0130\n",
            "Epoch 00006: val_loss improved from 0.01395 to 0.01370, saving model to regression__0.01303_0.01370_.hdf5\n",
            "4878/4878 [==============================] - 1430s 293ms/step - loss: 0.0130 - MSE: 0.0130 - val_loss: 0.0137 - val_MSE: 0.0137 - lr: 9.0300e-05\n",
            "Epoch 7/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0119 - MSE: 0.0119\n",
            "Epoch 00007: val_loss improved from 0.01370 to 0.01362, saving model to regression__0.01190_0.01362_.hdf5\n",
            "4878/4878 [==============================] - 1430s 293ms/step - loss: 0.0119 - MSE: 0.0119 - val_loss: 0.0136 - val_MSE: 0.0136 - lr: 8.8360e-05\n",
            "Epoch 8/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0111 - MSE: 0.0111\n",
            "Epoch 00008: val_loss improved from 0.01362 to 0.00994, saving model to regression__0.01113_0.00994_.hdf5\n",
            "4878/4878 [==============================] - 1507s 309ms/step - loss: 0.0111 - MSE: 0.0111 - val_loss: 0.0099 - val_MSE: 0.0099 - lr: 8.6420e-05\n",
            "Epoch 9/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0104 - MSE: 0.0104\n",
            "Epoch 00009: val_loss did not improve from 0.00994\n",
            "4878/4878 [==============================] - 1531s 314ms/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0118 - val_MSE: 0.0118 - lr: 8.4480e-05\n",
            "Epoch 10/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0097 - MSE: 0.0097\n",
            "Epoch 00010: val_loss improved from 0.00994 to 0.00974, saving model to regression__0.00968_0.00974_.hdf5\n",
            "4878/4878 [==============================] - 1585s 325ms/step - loss: 0.0097 - MSE: 0.0097 - val_loss: 0.0097 - val_MSE: 0.0097 - lr: 8.2540e-05\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 170)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12512)             2139552   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12512)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2156)              26978028  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 216)               465912    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 217       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,583,709\n",
            "Trainable params: 29,583,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0108 - MSE: 0.0108\n",
            "Epoch 00001: val_loss did not improve from 0.00974\n",
            "4878/4878 [==============================] - 1459s 299ms/step - loss: 0.0108 - MSE: 0.0108 - val_loss: 0.0110 - val_MSE: 0.0110 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0099 - MSE: 0.0099\n",
            "Epoch 00002: val_loss did not improve from 0.00974\n",
            "4878/4878 [==============================] - 1453s 298ms/step - loss: 0.0099 - MSE: 0.0099 - val_loss: 0.0118 - val_MSE: 0.0118 - lr: 9.8060e-05\n",
            "Epoch 3/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0092 - MSE: 0.0092\n",
            "Epoch 00003: val_loss did not improve from 0.00974\n",
            "4878/4878 [==============================] - 1454s 298ms/step - loss: 0.0092 - MSE: 0.0092 - val_loss: 0.0097 - val_MSE: 0.0097 - lr: 9.6120e-05\n",
            "Epoch 4/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0089 - MSE: 0.0089\n",
            "Epoch 00004: val_loss improved from 0.00974 to 0.00855, saving model to regression__0.00890_0.00855_.hdf5\n",
            "4878/4878 [==============================] - 1486s 305ms/step - loss: 0.0089 - MSE: 0.0089 - val_loss: 0.0085 - val_MSE: 0.0085 - lr: 9.4180e-05\n",
            "Epoch 5/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0085 - MSE: 0.0085\n",
            "Epoch 00005: val_loss did not improve from 0.00855\n",
            "4878/4878 [==============================] - 1487s 305ms/step - loss: 0.0085 - MSE: 0.0085 - val_loss: 0.0106 - val_MSE: 0.0106 - lr: 9.2240e-05\n",
            "Epoch 6/10\n",
            "4878/4878 [==============================] - ETA: 0s - loss: 0.0081 - MSE: 0.0081\n",
            "Epoch 00006: val_loss improved from 0.00855 to 0.00771, saving model to regression__0.00811_0.00771_.hdf5\n",
            "4878/4878 [==============================] - 1479s 303ms/step - loss: 0.0081 - MSE: 0.0081 - val_loss: 0.0077 - val_MSE: 0.0077 - lr: 9.0300e-05\n",
            "Epoch 7/10\n",
            "1300/4878 [======>.......................] - ETA: 17:56 - loss: 0.0074 - MSE: 0.0074"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    if __DNN_MODE__==\"regression\":\n",
        "        new_model_2.summary()\n",
        "        history=new_model_2.fit(X_train,\n",
        "          y_train,validation_data=(X_test,y_test),\n",
        "          epochs=10, \n",
        "          batch_size=3,\n",
        "          validation_split=0.1,\n",
        "          verbose=1,\n",
        "          callbacks=[callbacks,WandbCallback()],\n",
        "          shuffle=True\n",
        "          \n",
        "          )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihqdnY6Vm2Yd"
      },
      "outputs": [],
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lS9W3aAu2v8"
      },
      "outputs": [],
      "source": [
        "#new_model_2.load_weights(\"./_col_0.00098_0.00173_.xhdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVDad6L_Fgh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKodgIskMiCb"
      },
      "outputs": [],
      "source": [
        "new_model_2.load_weights(\"./regression__0.00420_0.00446_.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YcPfNhoDkVz"
      },
      "outputs": [],
      "source": [
        "y_pred=new_model_2.predict(X)\n",
        "result_df=pd.DataFrame()\n",
        "y_pred_col=[i[0] for i in y_pred]\n",
        "y_col=[i[0] for i in y]\n",
        "\n",
        "result_df[\"y\"]=y_col\n",
        "result_df[\"y_pred\"]=y_pred_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JvY2HWxIQQA"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(result_df, x=\"y\", y=\"y_pred\",width=600, height=400 )\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGqdbRn7lYIb"
      },
      "outputs": [],
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBgYvOPdECYF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score,mean_absolute_error\n",
        "\n",
        "\n",
        "clf = RandomForestRegressor(max_depth=70, random_state=0,n_estimators=300)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "randomforest_predict=clf.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxJVYoR0EJ5j"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy: {mean_absolute_error(y_train,randomforest_predict)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ski4ZlVBExqH"
      },
      "outputs": [],
      "source": [
        "randomforest_predict=clf.predict(X_test)\n",
        "print(f\"Accuracy: {mean_absolute_error(y_test,randomforest_predict)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cjQyvPz8Tz0"
      },
      "outputs": [],
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HFebOdZ_4Vp"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kls-KXivMt5K"
      },
      "outputs": [],
      "source": [
        "clf = LazyClassifier(verbose=1,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X[:-100], X[-100:], y[:-100], y[-100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDWbhHRM_r_t"
      },
      "outputs": [],
      "source": [
        "print(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuoQjjVD_Bwg"
      },
      "outputs": [],
      "source": [
        "yo=[i[0] for i in y_]\n",
        "yo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apnbaoAkC09G"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KPqXIiH-Ycc"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyRegressor\n",
        "reg = LazyRegressor(verbose=2, ignore_warnings=False, custom_metric=None)\n",
        "models,predictions = clf.fit(X[:-100], X[-100:], y[:-100], y[-100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4OdEx1rEAqx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Wn6o2lY80q5"
      },
      "outputs": [],
      "source": [
        "print(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHoy7pnWM84V"
      },
      "outputs": [],
      "source": [
        "x_counter=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tl2wZDeEWsD"
      },
      "outputs": [],
      "source": [
        "X_train=X[:-1*x_counter]\n",
        "X_test=X[-1*x_counter:]\n",
        "y_train=yo[:-1*x_counter]\n",
        "y_test =yo[-1*x_counter:]\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Blood_ldl_model_20211216.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}